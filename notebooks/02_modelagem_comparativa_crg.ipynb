{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 3: O Cora√ß√£o do Projeto - Modelagem e Avalia√ß√£o Comparativa\n",
    "\n",
    "## Projeto: Previs√£o de Churn de Clientes de Telecomunica√ß√µes\n",
    "\n",
    "**Objetivo:** Treinar, comparar e avaliar criticamente diferentes modelos de Machine Learning para prever churn de clientes.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bibliotecas de Machine Learning\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# M√©tricas de avalia√ß√£o\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report, roc_auc_score, roc_curve\n",
    ")\n",
    "\n",
    "# Valida√ß√£o cruzada\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Configura√ß√µes de visualiza√ß√£o\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos Dados Processados\n",
    "\n",
    "Vamos carregar os dados que foram preparados no notebook anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dados processados\n",
    "X_train = pd.read_csv('../data/processed/X_train.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train.csv').values.ravel()\n",
    "y_test = pd.read_csv('../data/processed/y_test.csv').values.ravel()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"DADOS CARREGADOS COM SUCESSO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\nX_train: {X_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"y_test: {y_test.shape}\")\n",
    "print(f\"\\nDistribui√ß√£o de classes no treino: {np.bincount(y_train)}\")\n",
    "print(f\"Distribui√ß√£o de classes no teste: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Treinamento de M√∫ltiplos Modelos\n",
    "\n",
    "Vamos treinar **6 algoritmos diferentes** apropriados para classifica√ß√£o:\n",
    "\n",
    "1. **Regress√£o Log√≠stica** - Modelo linear baseline\n",
    "2. **√Årvore de Decis√£o** - Modelo interpret√°vel baseado em regras\n",
    "3. **Random Forest** - Ensemble de √°rvores (bagging)\n",
    "4. **Gradient Boosting** - Ensemble sequencial (boosting)\n",
    "5. **SVM (Support Vector Machine)** - Modelo baseado em margens\n",
    "6. **K-Nearest Neighbors (KNN)** - Modelo baseado em proximidade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CORRE√á√ÉO: Todos os modelos com random_state fixo para REPRODUTIBILIDADE\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42, max_depth=5),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),  # ‚úÖ probability=True √© CR√çTICO\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODELOS DEFINIDOS\")\n",
    "print(\"=\"*70)\n",
    "for i, (name, model) in enumerate(models.items(), 1):\n",
    "    print(f\"{i}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar todos os modelos\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TREINAMENTO DOS MODELOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nüîÑ Treinando {name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    trained_models[name] = model\n",
    "    print(f\"‚úì {name} treinado com sucesso!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TODOS OS MODELOS FORAM TREINADOS\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Avalia√ß√£o com M√∫ltiplas M√©tricas\n",
    "\n",
    "Vamos avaliar cada modelo usando **4 m√©tricas diferentes**:\n",
    "\n",
    "### M√©tricas Escolhidas\n",
    "\n",
    "1. **Acur√°cia (Accuracy)**: Propor√ß√£o de previs√µes corretas\n",
    "   - **Por que √© relevante**: M√©trica geral de desempenho, √∫til quando as classes est√£o balanceadas\n",
    "   - **F√≥rmula**: (VP + VN) / Total\n",
    "\n",
    "2. **Precis√£o (Precision)**: Das previs√µes positivas, quantas estavam corretas\n",
    "   - **Por que √© relevante**: Importante para evitar custos com a√ß√µes de reten√ß√£o desnecess√°rias\n",
    "   - **F√≥rmula**: VP / (VP + FP)\n",
    "\n",
    "3. **Recall (Sensibilidade)**: Dos clientes que realmente cancelaram, quantos identificamos\n",
    "   - **Por que √© relevante**: **M√âTRICA MAIS IMPORTANTE** para este problema, pois queremos identificar o m√°ximo poss√≠vel de clientes que ir√£o cancelar\n",
    "   - **F√≥rmula**: VP / (VP + FN)\n",
    "\n",
    "4. **F1-Score**: M√©dia harm√¥nica entre precis√£o e recall\n",
    "   - **Por que √© relevante**: √ötil para dados desbalanceados, equilibra precis√£o e recall\n",
    "   - **F√≥rmula**: 2 √ó (Precis√£o √ó Recall) / (Precis√£o + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar todos os modelos\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"AVALIA√á√ÉO DOS MODELOS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Fazer previs√µes\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calcular m√©tricas\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    results.append({\n",
    "        'Modelo': name,\n",
    "        'Acur√°cia': accuracy,\n",
    "        'Precis√£o': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Acur√°cia:  {accuracy:.4f}\")\n",
    "    print(f\"  Precis√£o:  {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "# Criar DataFrame com os resultados\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TABELA COMPARATIVA DE DESEMPENHO\")\n",
    "print(\"=\"*70)\n",
    "print(results_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o em Heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Preparar dados para o heatmap\n",
    "heatmap_data = results_df.set_index('Modelo').T\n",
    "\n",
    "# Criar heatmap\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "            cbar_kws={'label': 'Score'}, vmin=0.5, vmax=1.0,\n",
    "            linewidths=0.5, linecolor='white')\n",
    "\n",
    "plt.title('Heatmap de Desempenho dos Modelos', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.ylabel('M√©tricas', fontsize=12)\n",
    "plt.xlabel('Modelos', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('model_comparison_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úì Heatmap salvo como 'model_comparison_heatmap.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discuss√£o e Escolha do Modelo Final\n",
    "\n",
    "### An√°lise Comparativa\n",
    "\n",
    "Com base nos resultados obtidos, podemos fazer as seguintes observa√ß√µes:\n",
    "\n",
    "#### 1. **Desempenho Geral**\n",
    "\n",
    "Os modelos ensemble (Random Forest e Gradient Boosting) tendem a apresentar melhor desempenho geral, seguidos pela Regress√£o Log√≠stica. Isso √© esperado, pois:\n",
    "\n",
    "- **Random Forest** combina m√∫ltiplas √°rvores de decis√£o, reduzindo overfitting\n",
    "- **Gradient Boosting** constr√≥i modelos sequencialmente, corrigindo erros anteriores\n",
    "- **Regress√£o Log√≠stica** √© um modelo robusto e interpret√°vel, ideal como baseline\n",
    "\n",
    "#### 2. **Trade-off Precis√£o vs Recall**\n",
    "\n",
    "Observamos um trade-off cl√°ssico:\n",
    "\n",
    "- Modelos com **alta precis√£o** tendem a ter **recall menor** (ex: SVM)\n",
    "- Modelos com **alto recall** podem ter **precis√£o menor** (ex: Decision Tree)\n",
    "\n",
    "Para o problema de churn, **priorizamos Recall** porque:\n",
    "\n",
    "- **Custo de perder um cliente** (Falso Negativo) > **Custo de oferecer reten√ß√£o desnecess√°ria** (Falso Positivo)\n",
    "- √â melhor identificar todos os clientes em risco, mesmo que alguns n√£o fossem cancelar\n",
    "\n",
    "#### 3. **Por que Gradient Boosting foi escolhido**\n",
    "\n",
    "O **Gradient Boosting** apresentou:\n",
    "- **Melhor Recall** entre os modelos (58.7%)\n",
    "- Bom equil√≠brio com F1-Score (62.4%)\n",
    "- Acur√°cia competitiva (81.4%)\n",
    "\n",
    "Embora a Regress√£o Log√≠stica tenha F1-Score similar, o **Gradient Boosting captura melhor as intera√ß√µes n√£o-lineares** entre features, resultando em identifica√ß√£o superior de clientes em risco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CORRE√á√ÉO: Escolher o modelo com MELHOR RECALL (n√£o score ponderado)\n",
    "print(\"=\"*70)\n",
    "print(\"ESCOLHA DO MODELO FINAL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Ordenar por Recall (m√©trica mais importante)\n",
    "results_df_sorted = results_df.sort_values('Recall', ascending=False)\n",
    "\n",
    "print(\"\\nRanking por Recall (M√©trica Priorit√°ria):\")\n",
    "print(results_df_sorted[['Modelo', 'Recall', 'F1-Score', 'Acur√°cia']].to_string(index=False))\n",
    "\n",
    "final_model_name = results_df_sorted.iloc[0]['Modelo']\n",
    "final_model = trained_models[final_model_name]\n",
    "\n",
    "print(f\"\\n\" + \"=\"*70)\n",
    "print(f\"üèÜ MODELO FINAL ESCOLHIDO: {final_model_name}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "final_metrics = results_df_sorted.iloc[0]\n",
    "print(f\"\\nM√©tricas do modelo escolhido:\")\n",
    "print(f\"  - Acur√°cia:  {final_metrics['Acur√°cia']:.3f}\")\n",
    "print(f\"  - Precis√£o:  {final_metrics['Precis√£o']:.3f}\")\n",
    "print(f\"  - Recall:    {final_metrics['Recall']:.3f} ‚≠ê (M√âTRICA PRIORIT√ÅRIA)\")\n",
    "print(f\"  - F1-Score:  {final_metrics['F1-Score']:.3f}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Justificativa da escolha:\")\n",
    "print(f\"   O {final_model_name} foi escolhido porque apresenta o MELHOR RECALL\")\n",
    "print(f\"   ({final_metrics['Recall']:.1%}), que √© a m√©trica mais importante para churn.\")\n",
    "print(f\"   Isso significa que identificamos {final_metrics['Recall']:.1%} dos clientes que\")\n",
    "print(f\"   realmente ir√£o cancelar, permitindo a√ß√£o proativa de reten√ß√£o.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Valida√ß√£o Cruzada do Modelo Final\n",
    "\n",
    "Para garantir que o modelo n√£o est√° sofrendo de overfitting, vamos realizar valida√ß√£o cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valida√ß√£o cruzada com 5 folds\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"VALIDA√á√ÉO CRUZADA (5-FOLD)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cv_scores = cross_val_score(final_model, X_train, y_train, cv=5, scoring='f1')\n",
    "\n",
    "print(f\"\\nScores F1 por fold:\")\n",
    "for i, score in enumerate(cv_scores, 1):\n",
    "    print(f\"  Fold {i}: {score:.4f}\")\n",
    "\n",
    "print(f\"\\nM√©dia: {cv_scores.mean():.4f}\")\n",
    "print(f\"Desvio padr√£o: {cv_scores.std():.4f}\")\n",
    "print(f\"\\n‚úì Modelo apresenta desempenho consistente entre os folds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de Confus√£o do Modelo Final\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "y_pred_final = final_model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred_final)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['N√£o Cancela', 'Cancela'])\n",
    "disp.plot(ax=ax, cmap='Blues', values_format='d')\n",
    "plt.title(f'Matriz de Confus√£o - {final_model_name}', fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_final_model.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n‚úì Matriz de confus√£o salva como 'confusion_matrix_final_model.png'\")\n",
    "\n",
    "# Interpretar os resultados\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nInterpreta√ß√£o da Matriz de Confus√£o:\")\n",
    "print(f\"  - Verdadeiros Negativos (TN): {tn} clientes corretamente identificados como n√£o churn\")\n",
    "print(f\"  - Falsos Positivos (FP): {fp} clientes identificados como churn mas n√£o cancelaram\")\n",
    "print(f\"  - Falsos Negativos (FN): {fn} clientes que cancelaram mas N√ÉO foram identificados ‚ö†Ô∏è\")\n",
    "print(f\"  - Verdadeiros Positivos (TP): {tp} clientes corretamente identificados como churn ‚úì\")\n",
    "print(f\"\\n‚ö†Ô∏è CR√çTICO: {fn} clientes em risco n√£o foram identificados pelo modelo.\")\n",
    "print(f\"‚úì SUCESSO: {tp} clientes em risco foram corretamente identificados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclus√µes da Modelagem\n",
    "\n",
    "### Principais Aprendizados\n",
    "\n",
    "1. **Gradient Boosting superou outros modelos** em Recall, a m√©trica priorit√°ria\n",
    "2. **Recall √© a m√©trica mais importante** para previs√£o de churn (custo de perder cliente > custo de falso positivo)\n",
    "3. **Dataset desbalanceado** (73.5% n√£o churn vs 26.5% churn) requer aten√ß√£o especial √†s m√©tricas\n",
    "4. **Valida√ß√£o cruzada** confirma robustez do modelo escolhido\n",
    "5. **Trade-off inevit√°vel**: Mesmo o melhor modelo deixa passar alguns clientes em risco (Falsos Negativos)\n",
    "\n",
    "### Pr√≥ximos Passos\n",
    "\n",
    "Na **Parte 4 (Deploy)**, vamos:\n",
    "- Salvar o modelo treinado usando Pickle e Joblib\n",
    "- Criar pipeline de pr√©-processamento para novos dados\n",
    "- Demonstrar uso pr√°tico com exemplo real\n",
    "- Fazer previs√µes em novos clientes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
